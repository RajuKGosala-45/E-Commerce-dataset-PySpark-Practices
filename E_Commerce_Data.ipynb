{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFuLchytVUs0kAFUObg7lb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajuKGosala-45/E-Commerce-dataset-PySpark-Practices/blob/main/E_Commerce_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark Install in Google Collab"
      ],
      "metadata": {
        "id": "HPsWsc2bkHkE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU_bLeWrj3-Q",
        "outputId": "d0787efe-4fad-424e-b6da-da129138a177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-17-jdk-headless_17.0.17+10-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk-headless:amd64 (17.0.17+10-1~22.04) over (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "Preparing to unpack .../openjdk-17-jre-headless_17.0.17+10-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jre-headless:amd64 (17.0.17+10-1~22.04) over (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "Setting up openjdk-17-jre-headless:amd64 (17.0.17+10-1~22.04) ...\n",
            "Installing new version of config file /etc/java-17-openjdk/security/default.policy ...\n",
            "Installing new version of config file /etc/java-17-openjdk/security/java.security ...\n",
            "Setting up openjdk-17-jdk-headless:amd64 (17.0.17+10-1~22.04) ...\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -qq\n",
        "!apt-get install -y openjdk-17-jdk-headless -qq\n",
        "\n",
        "!pip install pyspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] += \":/usr/lib/jvm/java-17-openjdk-amd64/bin\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up SparkSession and Load Data"
      ],
      "metadata": {
        "id": "7V6Wbz3QkRti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "spark = SparkSession.builder.appName(\"E-Commerce Bussiness\").getOrCreate()\n",
        "\n",
        "Files ={\n",
        "    \"events\":\"/content/events.csv\",\n",
        "    \"order_items\":\"/content/order_items.csv\",\n",
        "    \"orders\":\"/content/orders.csv\",\n",
        "    \"products\":\"/content/products.csv\",\n",
        "    \"reviews\":\"/content/reviews.csv\",\n",
        "    \"users\":\"/content/users.csv\"\n",
        "}\n",
        "\n",
        "df= {name: spark.read.csv(path, header=True, inferSchema=True) for name, path in Files.items()}"
      ],
      "metadata": {
        "id": "48kwwA4Ej9Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print Schema and Sample"
      ],
      "metadata": {
        "id": "eBgqI9ghlccm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in df.items():\n",
        "  print(f\"\\n Dataset: {name.upper()}\")\n",
        "  df.printSchema()\n",
        "  df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA88QdAHj9OD",
        "outputId": "d6b3384f-426f-4ba2-cbd3-3b960d8eb6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Dataset: EVENTS-----------------\n",
            "root\n",
            " |-- event_id: string (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- event_type: string (nullable = true)\n",
            " |-- event_timestamp: timestamp (nullable = true)\n",
            "\n",
            "+---------+-------+----------+----------+--------------------+\n",
            "| event_id|user_id|product_id|event_type|     event_timestamp|\n",
            "+---------+-------+----------+----------+--------------------+\n",
            "|E00000001|U009798|   P001393|      cart|2025-07-08 14:28:...|\n",
            "|E00000002|U005881|   P000669|      view|2025-10-19 23:00:...|\n",
            "|E00000003|U006348|   P001404|      view|2025-05-09 07:02:...|\n",
            "|E00000004|U002664|   P000400|      cart|2025-07-19 22:47:...|\n",
            "|E00000005|U005776|   P000392|      view|2024-10-24 10:20:...|\n",
            "+---------+-------+----------+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            " Dataset: ORDER_ITEMS-----------------\n",
            "root\n",
            " |-- order_item_id: string (nullable = true)\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- quantity: integer (nullable = true)\n",
            " |-- item_price: double (nullable = true)\n",
            " |-- item_total: double (nullable = true)\n",
            "\n",
            "+-------------+---------+----------+-------+--------+----------+----------+\n",
            "|order_item_id| order_id|product_id|user_id|quantity|item_price|item_total|\n",
            "+-------------+---------+----------+-------+--------+----------+----------+\n",
            "|    I00000001|O00000001|   P001758|U009310|       2|      8.07|     16.14|\n",
            "|    I00000002|O00000001|   P001119|U009310|       1|     74.08|     74.08|\n",
            "|    I00000003|O00000001|   P001794|U009310|       1|    576.97|    576.97|\n",
            "|    I00000004|O00000001|   P001038|U009310|       1|     22.47|     22.47|\n",
            "|    I00000005|O00000002|   P000859|U003247|       1|    422.22|    422.22|\n",
            "+-------------+---------+----------+-------+--------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            " Dataset: ORDERS-----------------\n",
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- order_date: timestamp (nullable = true)\n",
            " |-- order_status: string (nullable = true)\n",
            " |-- total_amount: double (nullable = true)\n",
            "\n",
            "+---------+-------+--------------------+------------+------------+\n",
            "| order_id|user_id|          order_date|order_status|total_amount|\n",
            "+---------+-------+--------------------+------------+------------+\n",
            "|O00000001|U009310|2025-09-09 14:52:...|  processing|      689.66|\n",
            "|O00000002|U003247|2025-04-15 01:18:...|   completed|     1666.85|\n",
            "|O00000003|U007252|2025-04-27 15:37:...|  processing|      665.06|\n",
            "|O00000004|U008986|2025-10-04 20:35:...|   cancelled|       689.5|\n",
            "|O00000005|U008537|2024-11-13 08:15:...|   cancelled|       860.5|\n",
            "+---------+-------+--------------------+------------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            " Dataset: PRODUCTS-----------------\n",
            "root\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- product_name: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- brand: string (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            "\n",
            "+----------+---------------+--------------+-------+------+------+\n",
            "|product_id|   product_name|      category|  brand| price|rating|\n",
            "+----------+---------------+--------------+-------+------+------+\n",
            "|   P000001|       Astra Be|      Clothing|  Astra|157.89|  4.08|\n",
            "|   P000002|NeoTech Someone|     Groceries|NeoTech| 21.46|  3.87|\n",
            "|   P000003|   Acme Discuss|        Sports|   Acme|265.37|  3.46|\n",
            "|   P000004|   Nimbus South|   Electronics| Nimbus|541.41|  4.14|\n",
            "|   P000005|  Astra Capital|Home & Kitchen|  Astra| 198.0|  3.97|\n",
            "+----------+---------------+--------------+-------+------+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            " Dataset: REVIEWS-----------------\n",
            "root\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- rating: integer (nullable = true)\n",
            " |-- review_text: string (nullable = true)\n",
            " |-- review_date: timestamp (nullable = true)\n",
            "\n",
            "+---------+---------+----------+-------+------+--------------------+--------------------+\n",
            "|review_id| order_id|product_id|user_id|rating|         review_text|         review_date|\n",
            "+---------+---------+----------+-------+------+--------------------+--------------------+\n",
            "|R00000528|O00000237|   P001326|U001094|     2|Color was differe...|2025-10-14 12:03:...|\n",
            "|R00005792|O00002627|   P000329|U001858|     4|Highly recommend ...|2024-10-09 08:04:...|\n",
            "|R00036604|O00016798|   P001160|U008109|     4|Highly recommend ...|2024-06-03 05:11:...|\n",
            "|R00040163|O00018414|   P001427|U006835|     5|Highly recommend ...|2024-02-12 06:41:...|\n",
            "|R00031127|O00014300|   P001639|U007148|     3|Item arrived dama...|2025-01-20 05:32:...|\n",
            "+---------+---------+----------+-------+------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            " Dataset: USERS-----------------\n",
            "root\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- email: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- signup_date: date (nullable = true)\n",
            "\n",
            "+-------+--------------+--------------------+------+----------------+-----------+\n",
            "|user_id|          name|               email|gender|            city|signup_date|\n",
            "+-------+--------------+--------------------+------+----------------+-----------+\n",
            "|U000001|    Angel Hill|donaldgarcia@exam...| Other|  New Roberttown| 2025-03-13|\n",
            "|U000002|  Jesse Guzman|jennifermiles@exa...|  Male|   South Bridget| 2024-03-05|\n",
            "|U000003|  Adam Shaffer|jpeterson@example...|  Male|      Curtisfurt| 2025-07-07|\n",
            "|U000004| Melanie Munoz|blairamanda@examp...| Other|   New Kellystad| 2024-03-07|\n",
            "|U000005|Janet Williams|kendragalloway@ex...|Female|South Joshuastad| 2025-01-29|\n",
            "+-------+--------------+--------------------+------+----------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Missing Values Summary"
      ],
      "metadata": {
        "id": "JqQ6xJ6kl8mH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = {name: spark.read.csv(path, header=True, inferSchema=True) for name, path in Files.items()}\n",
        "\n",
        "for name, current_df in df.items():\n",
        "  print(f\"\\n Missing Values Summary For: {name.upper()}\")\n",
        "\n",
        "  null_expressions = []\n",
        "  for field in current_df.schema:\n",
        "    column_name = field.name\n",
        "\n",
        "    # Start with the isNull() check for all column types\n",
        "    condition = col(column_name).isNull()\n",
        "\n",
        "    # Add check for empty strings if the column is of StringType\n",
        "    if isinstance(field.dataType, StringType):\n",
        "      condition = condition | (col(column_name) == \"\")\n",
        "\n",
        "    # Add check for NaN if the column is of NumericType\n",
        "    # NumericType includes DoubleType, FloatType, IntegerType, etc.\n",
        "    if isinstance(field.dataType, NumericType):\n",
        "      condition = condition | isnan(col(column_name))\n",
        "\n",
        "    null_expressions.append(\n",
        "        (count(when(condition, col(column_name))) / current_df.count() * 100).alias(column_name)\n",
        "    )\n",
        "\n",
        "  null_df = current_df.select(null_expressions)\n",
        "  null_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vyd8p9gSnTIo",
        "outputId": "cc7d1591-daf0-46e6-f1c9-be776c9f16e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Missing Values Summary For: EVENTS\n",
            "+--------+-------+----------+----------+---------------+\n",
            "|event_id|user_id|product_id|event_type|event_timestamp|\n",
            "+--------+-------+----------+----------+---------------+\n",
            "|     0.0|    0.0|       0.0|       0.0|            0.0|\n",
            "+--------+-------+----------+----------+---------------+\n",
            "\n",
            "\n",
            " Missing Values Summary For: ORDER_ITEMS\n",
            "+-------------+--------+----------+-------+--------+----------+----------+\n",
            "|order_item_id|order_id|product_id|user_id|quantity|item_price|item_total|\n",
            "+-------------+--------+----------+-------+--------+----------+----------+\n",
            "|          0.0|     0.0|       0.0|    0.0|     0.0|       0.0|       0.0|\n",
            "+-------------+--------+----------+-------+--------+----------+----------+\n",
            "\n",
            "\n",
            " Missing Values Summary For: ORDERS\n",
            "+--------+-------+----------+------------+------------+\n",
            "|order_id|user_id|order_date|order_status|total_amount|\n",
            "+--------+-------+----------+------------+------------+\n",
            "|     0.0|    0.0|       0.0|         0.0|         0.0|\n",
            "+--------+-------+----------+------------+------------+\n",
            "\n",
            "\n",
            " Missing Values Summary For: PRODUCTS\n",
            "+----------+------------+--------+-----+-----+------+\n",
            "|product_id|product_name|category|brand|price|rating|\n",
            "+----------+------------+--------+-----+-----+------+\n",
            "|       0.0|         0.0|     0.0|  0.0|  0.0|   0.0|\n",
            "+----------+------------+--------+-----+-----+------+\n",
            "\n",
            "\n",
            " Missing Values Summary For: REVIEWS\n",
            "+---------+--------+----------+-------+------+-----------+-----------+\n",
            "|review_id|order_id|product_id|user_id|rating|review_text|review_date|\n",
            "+---------+--------+----------+-------+------+-----------+-----------+\n",
            "|      0.0|     0.0|       0.0|    0.0|   0.0|        0.0|        0.0|\n",
            "+---------+--------+----------+-------+------+-----------+-----------+\n",
            "\n",
            "\n",
            " Missing Values Summary For: USERS\n",
            "+-------+----+-----+------+----+-----------+\n",
            "|user_id|name|email|gender|city|signup_date|\n",
            "+-------+----+-----+------+----+-----------+\n",
            "|    0.0| 0.0|  0.0|   0.0| 0.0|        0.0|\n",
            "+-------+----+-----+------+----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Duplicate check Using primary Keys"
      ],
      "metadata": {
        "id": "f93-BaY1phsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Primary_keys ={\n",
        "    \"users\":\"user_id\",\n",
        "    \"orders\":\"order_id\",\n",
        "    \"order_items\":\"order_item_id\",\n",
        "    \"products\":\"product_id\",\n",
        "    \"reviews\":\"review_id\",\n",
        "    \"events\":\"event_id\"\n",
        "}\n",
        "\n",
        "for name, df in df.items():\n",
        "  key = Primary_keys.get(name)\n",
        "  if key:\n",
        "    dup_count = df.groupBy(key).count().filter(\"count > 1\").count()\n",
        "    print(f\"Duplicate {key} in {name}: {dup_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI1vkoXpp_8A",
        "outputId": "0dbf91a5-fc36-4a41-cdc2-dcfe67fed72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate event_id in events: 0\n",
            "Duplicate order_item_id in order_items: 0\n",
            "Duplicate order_id in orders: 0\n",
            "Duplicate product_id in products: 0\n",
            "Duplicate review_id in reviews: 0\n",
            "Duplicate user_id in users: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistical summary Stats for Numerical Columns\n"
      ],
      "metadata": {
        "id": "_uqfBYc-rAcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in df.items():\n",
        "  print(f\"\\n Summary Stats for: {name.upper()}\")\n",
        "  numeric_cols = [c for c, t in df.dtypes if t in (\"int\",\"bigint\",\"double\",\"float\")]\n",
        "  if numeric_cols:\n",
        "    df.select(numeric_cols).describe().show()\n",
        "print(\"\\n Day 51 Completed - Data Profilling Done \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJs8hh8TrH6w",
        "outputId": "cb5cb761-8823-4886-da45-fa362076566c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Summary Stats for: EVENTS\n",
            "\n",
            " Summary Stats for: ORDER_ITEMS\n",
            "+-------+------------------+------------------+-----------------+\n",
            "|summary|          quantity|        item_price|       item_total|\n",
            "+-------+------------------+------------------+-----------------+\n",
            "|  count|             43525|             43525|            43525|\n",
            "|   mean|1.3973118897185526|196.63697622056128|273.8350132108008|\n",
            "| stddev|0.6607172757815206|  297.259223858562|471.5851039154428|\n",
            "|    min|                 1|              1.11|             1.11|\n",
            "|    max|                 3|           2338.13|          7014.39|\n",
            "+-------+------------------+------------------+-----------------+\n",
            "\n",
            "\n",
            " Summary Stats for: ORDERS\n",
            "+-------+-----------------+\n",
            "|summary|     total_amount|\n",
            "+-------+-----------------+\n",
            "|  count|            20000|\n",
            "|   mean|595.9334475000019|\n",
            "| stddev|776.0633359009934|\n",
            "|    min|             1.11|\n",
            "|    max|          7950.74|\n",
            "+-------+-----------------+\n",
            "\n",
            "\n",
            " Summary Stats for: PRODUCTS\n",
            "+-------+------------------+------------------+\n",
            "|summary|             price|            rating|\n",
            "+-------+------------------+------------------+\n",
            "|  count|              2000|              2000|\n",
            "|   mean|200.34223000000011|3.6776149999999994|\n",
            "| stddev|302.74239544789185|0.6864775943312065|\n",
            "|    min|              1.11|               2.5|\n",
            "|    max|           2338.13|               4.9|\n",
            "+-------+------------------+------------------+\n",
            "\n",
            "\n",
            " Summary Stats for: REVIEWS\n",
            "+-------+------------------+\n",
            "|summary|            rating|\n",
            "+-------+------------------+\n",
            "|  count|             15000|\n",
            "|   mean|3.5446666666666666|\n",
            "| stddev|1.1036693774081674|\n",
            "|    min|                 1|\n",
            "|    max|                 5|\n",
            "+-------+------------------+\n",
            "\n",
            "\n",
            " Summary Stats for: USERS\n",
            "\n",
            " Day 51 Completed - Data Profilling Done \n"
          ]
        }
      ]
    }
  ]
}